# 🔍 调试功能使用指南

## 概述

调试功能允许你查看每个 AI 评委在评分过程中收到的完整请求上下文和回复详情，帮助你理解和优化评委的行为。

## 功能特点

### 📊 阶段一：独立评分详情

对于每个评委，你可以查看：

1. **请求上下文**
   - **System Message**：评委收到的系统消息（评分规范 + 评委人设）
   - **User Instruction**：用户发送的指令内容（包括作品信息和图片描述）

2. **回复详情**
   - 评分结果（总分、各维度分数）
   - 一句话点评
   - 详细评语
   - 优点和缺点列表
   - **Raw Output**：AI 模型的原始 JSON 输出（可复制）

3. **元数据**
   - 使用的模型名称
   - 评委 ID 和显示名称
   - 创建时间

### 💬 阶段二：群聊讨论详情

你可以查看：

1. **群聊上下文**
   - **Initial Message**：初始消息（包含所有评委的初评结果汇总）
   - **Selector Prompt**：选择器的提示词（AutoGen 用于选择下一个发言评委）

2. **评委配置**
   - 每个评委在群聊中的 System Message（人设 + 讨论模式说明）
   - 使用的模型名称
   - 评委显示名称

3. **对话记录**
   - 完整的对话记录（按顺序编号）
   - 每条消息的发言者和内容
   - 自动显示评委显示名称

## 使用方法

### 方法一：从主页面访问

1. 在主页面提交作品并完成评分
2. 在结果页面，点击 **「🔍 查看调试详情」** 按钮
3. 系统会打开调试页面，显示该作品的完整调试信息

### 方法二：直接访问

如果你知道作品的 `entry_id`，可以直接访问：

```
http://localhost:8000/debug.html?entry_id=your_entry_id
```

### 方法三：通过 API

你也可以通过 API 获取 JSON 格式的调试数据：

```bash
curl http://localhost:8000/api/debug/entry/{entry_id}
```

## 调试页面功能

### Tab 切换

- **阶段一：独立评分** - 查看每个评委的独立评分详情
- **阶段二：群聊讨论** - 查看评委们的群聊讨论内容

### 可折叠内容

- **查看请求上下文 ▼** - 展开/折叠评委收到的完整请求
- **查看回复详情 ▼** - 展开/折叠评委的回复和评分

### 复制功能

在 Raw Output 区域，点击 **「复制」** 按钮可以快速复制原始输出内容。

## 使用场景

### 🎯 优化评委提示词

1. 查看 System Message，了解评委实际收到的完整提示词
2. 对比不同评委的回复，评估提示词效果
3. 根据 Raw Output 调整评分规范和评委人设

### 🐛 调试评分问题

1. 查看某个评委的异常评分
2. 检查 Raw Output 是否符合预期的 JSON 格式
3. 查看 User Instruction 是否正确传达了作品信息

### 📈 分析评委行为

1. 对比不同评委对同一作品的评价
2. 分析评委在群聊中的发言策略
3. 评估不同模型的表现差异

### 🔧 开发和测试

1. 验证新增的评分维度是否生效
2. 测试自定义提示词的效果
3. 调试模型调用问题

## 数据说明

### 保存的调试信息

系统会自动保存以下信息到数据库：

- `system_message` - 评委收到的系统消息
- `user_instruction` - 用户指令内容
- `model_name` - 使用的 AI 模型名称
- `debug_context` - 其他调试上下文（如评分规范、评委人设）
- `raw_output` - AI 模型的原始输出

### 数据持久化

- 所有调试信息都保存在 SQLite 数据库中
- 每次重新提交相同的 `entry_id` 会覆盖旧数据
- 可以通过删除数据库文件 (`show5.db`) 来清空所有数据

## API 端点

### GET /api/debug/entry/{entry_id}

返回指定作品的完整调试信息。

**响应结构：**

```json
{
  "entry_id": "test_001",
  "image_url": "https://example.com/image.jpg",
  "competition_type": "outfit",
  "extra_text": "补充说明",
  "created_at": "2025-11-20T10:00:00",
  
  "stage_one": {
    "judges": [
      {
        "judge_id": "chatgpt5_judge",
        "judge_display_name": "ChatGPT-5 评委",
        "model_name": "gpt-4o",
        "request_context": {
          "system_message": "完整的系统消息...",
          "user_instruction": "用户指令...",
          "debug_context": { ... }
        },
        "response": {
          "overall_score": 8.5,
          "one_liner": "一句话点评",
          "comment_for_audience": "详细评语",
          "raw_output": "原始JSON输出..."
        }
      }
    ]
  },
  
  "stage_two": {
    "debate_sessions": [
      {
        "debate_id": "test_001_debate",
        "participants": ["chatgpt5_judge", "grok_judge"],
        "messages": [
          {
            "sequence": 1,
            "speaker": "chatgpt5_judge",
            "content": "发言内容..."
          }
        ]
      }
    ]
  }
}
```

## 注意事项

⚠️ **隐私和安全**
- 调试信息包含完整的系统提示词和 API 响应
- 生产环境请考虑添加访问控制
- 敏感信息（如 API Key）不会被保存

⚠️ **性能**
- 调试信息会增加数据库存储空间
- 对于大量作品，建议定期清理旧数据

⚠️ **数据一致性**
- 如果修改了评分规范或评委人设，只有新提交的作品会使用新配置
- 已保存的调试信息不会自动更新

## 故障排除

### 调试页面无法加载

检查：
1. 后端服务是否正常运行
2. `entry_id` 是否存在
3. 浏览器控制台是否有错误信息

### 没有调试信息

可能原因：
1. 该作品是在更新前提交的（旧数据没有调试信息）
2. 评分过程中出现了错误
3. 数据库被清空或重新初始化

解决方法：
- 重新提交作品进行评分
- 检查后端日志 (`logs/server.log`)

### Raw Output 格式异常

可能原因：
1. AI 模型没有按照 JSON 格式输出
2. 输出被截断
3. 模型出现了错误

解决方法：
- 查看完整的 Raw Output
- 检查评分规范是否清晰指定了输出格式
- 尝试不同的模型

## 反馈和改进

如果你有任何建议或发现问题，欢迎：
- 查看项目文档
- 提交 Issue
- 贡献代码

Happy Debugging! 🎉

